Office Hours 10 11-4

Rescores and feedback requests on Assignment 1

Assignment 2 almost done

Supplemental Readings Important
    Survey on reductionality techniques, read for theor

# Assignment 4

* Interestingness on MDP
* Value Iteration and Policy Iteration implemented MDP domain, model based
* Same MDP, RL learning
    * Q learning typical
* Talk about MDP problems
    * Brief description, why they are interesting
        * structure, states, action space, hypothesis on Q learning challenges
            * epsilon and decay - tuning issues
        * 
    * Gridworld 
    * Non-gridworld - openai gym several non-gridworld problems
* Python - mdptoolbox, hiive fork!!!!
    * Has runners
* VI \ PI on both (model based)
    * convergence - use plot to discuss, reward vs iteration
        * delta vs iteration 
            * capture how delta gets smaller
    * Visualize or describe policies !!!
    * See if there are differnces !!!
* Choosing mdps
    * small \ large moddle based
    * use large and small space with each problem
    * vary state space size, how performance changes, how convergence and policy changes
* Discuss convergence
    * include plots
    * exploration strategies
        * epsilon \ decay
        * show policies
* Compare and contrast accross
    * differences in behavior
    * best , most robost to domain
    * model based vs 
    reward against time, state space against time
    exploration \ exploitation tradeoff - discuss this, can go deeper
    Hyperparameter tuning - using different gammas, highlight outcome differences, also epsilon and decay
* Overview 