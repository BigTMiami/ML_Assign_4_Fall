todo
check on nd for PI - if 0
change charts for forest
heatmaps with same colorbar

forest 
iteration vs # states pi vs vi
time vs # states pi vs vi

can we check V change to deterimine stable policy in vi


convergence uses max_iter limit calculation - what is this
max_iter governed by gamma, and epsilon.  max_iters is the necessary amount to get to it
how do we know if epsilon threshold for vi is optimal policy?
lower epsilon until policy doesn't change

show rate of change

iteration 

state size vs time

discount, max reward, epsilon / error vs max_iter

forest - essentially one best policy
lake - many maps may have several best policies



policy iteration doesn't converge, but ossiclates
try modified pi to allow convergence using threshold?

# Q learning
    
Modifiy to always start in state 0 to better model real life

Forest is challenging - each step initially the right thing to do is to cut